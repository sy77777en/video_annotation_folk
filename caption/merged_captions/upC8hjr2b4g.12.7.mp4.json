{
  "video_id": "upC8hjr2b4g.12.7.mp4",
  "merged_caption": "The video begins with a full shot of a computer monitor positioned in the middle ground, occupying the frame from the left edge to the right. Centrally displayed on the monitor are four horizontally stacked graphs, each featuring a bright yellow waveform that continuously scrolls from right to left, representing EEG data. Overlay text is visible in the bottom-left corner of the screen, reading \"[2]; gtec medical engineering - Comparing the different approaches of EEG data visualization (2023)\". The monitor is set against a textured wall in a dimly lit room with a green ambiance. The camera, from a high, eye-level angle, moves forward unsteadily, using a shallow depth of field to keep the focus on the EEG monitor in the midground. As the camera advances, it brings the viewer closer to the monitor, causing part of the monitor's frame to go out of view, yet it still qualifies as a full shot. The bright yellow lines on the graphs fluctuate erratically up and down, creating distinct, jagged wave patterns as they progress across the black background with a white grid. Numerical scales are visible on the vertical axes of each graph, with labels \"100,\" \"50,\" \"0,\" and \"-50\" to the left. In the foreground on the right, a blurred, light-colored, smooth, curved object partially obscures the monitor, reflecting the ambient green-tinged light. The camera remains at the monitor's level, maintaining focus on the dynamic display of the EEG data.",
  "input_captions": {
    "Camera": "From a high, eye-level angle, the unsteady camera moves forward. It uses a shallow depth of field, keeping the focus on the EEG monitor in the midground.",
    "Subject": "The video displays a close-up of a dark monitor screen, which shows four distinct horizontal graphs. Each graph features a bright yellow, fluctuating line representing electroencephalogram (EEG) data, plotted against a black background. A fine white grid is overlaid on each graph, and white numerical labels for the y-axis, including \"100,\" \"50,\" \"0,\" and \"-50,\" are visible to the left. At the bottom left corner of the screen, there is a line of small, white text. Partially visible on the right side of the screen is a blurred, light-colored, smooth, curved object, reflecting the ambient green-tinged light.",
    "Motion": "On the monitor, four bright yellow lines representing EEG data continuously scroll from right to left across the screen. Each line fluctuates erratically up and down, creating a distinct, jagged wave pattern as it progresses.",
    "Scene": "In a dimly lit room with a green ambiance, a computer monitor displays four horizontally stacked graphs. The graphs feature a black background with a white grid, upon which bright yellow, fluctuating waveforms scroll continuously from right to left. Numerical scales are visible on the vertical axes of each graph. The monitor is positioned against a textured wall, and the right side of the view is partially obscured by a smooth, white, curved surface. An overlay in the bottom-left corner of the screen displays the text \"[2]; gtec medical engineering - Comparing the different approaches of EEG data visualization (2023)\".",
    "Spatial": "The video begins with a full shot of a computer monitor positioned in the middle ground, occupying the frame from the left edge to the right. Centrally displayed on the monitor are four horizontally stacked graphs, each featuring a bright yellow waveform that continuously scrolls from right to left. Overlay text is visible in the bottom-left corner of the screen. As the camera moves forward, it brings the viewer closer to the monitor, causing part of the monitor's frame to go out of view, yet it still qualifies as a full shot. In the foreground on the right, a blurred, curved object partially obscures the monitor. The camera remains at the monitor's level."
  },
  "prompt": "Please merge the following five captions into a single, comprehensive caption that describes the video completely without any redundancy.\n\nCaption Types:\n1. Subject: Describes the subjects/people in the video\n2. Scene: Describes the scene composition and environment\n3. Motion: Describes the movement and dynamics of subjects\n4. Spatial: Describes the spatial relationships and framing\n5. Camera: Describes camera movements and framing choices\n\nInput Captions:\n{captions}\n\nInstructions:\n1. Use the SPATIAL caption as your BASE structure - it provides the core visual description and framing\n2. Merge MOTION and CAMERA captions into the spatial description to create a temporally coherent narrative that describes how things change over time\n3. Add information from SUBJECT and SCENE captions ONLY if they contain unique details not already covered in the Spatial caption\n4. Eliminate ALL redundant information - if the same detail appears in multiple captions, mention it only ONCE\n5. Preserve the EXACT wording from the original captions - do NOT paraphrase\n6. When describing temporal changes, integrate motion and camera movements in chronological order to show how the scene evolves\n7. CRITICAL: Every unique detail from all five captions must appear in the final merged caption - nothing should be omitted\n8. Do NOT add any information not present in the original captions\n9. Return only the merged caption without any additional text or formatting\n\nGoal: A single, temporally coherent caption based on the Spatial description, with Motion and Camera information merged chronologically, and Subject/Scene details added only when they provide new information. Keep as many details as possible but limit to at most 320 words.",
  "llm_model": "gpt-4o-2024-08-06",
  "timestamp": "2025-10-26T07:28:44.266231",
  "input_token_count": 502,
  "input_word_count": 377,
  "output_token_count": 320,
  "output_word_count": 240
}